{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kauhe\\AppData\\Local\\Temp\\ipykernel_31024\\994947822.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('./torch-cache/test_12_wcls.ckpt', map_location=torch.device(device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 109489161\n",
      "Authors list: ['dekker', 'fletcher', 'ford', 'jonson', 'massinger', 'middleton', 'rowley', 'shakespeare', 'webster']\n",
      "model running on cuda\n"
     ]
    }
   ],
   "source": [
    "# LOAD FINE-TUNED MODEL FROM DISK\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = torch.load('./torch-cache/test_12_wcls.ckpt', map_location=torch.device(device))\n",
    "print(f\"Total number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "with open('./torch-cache/authors.json') as file:\n",
    "    authors = json.load(file)\n",
    "    print(f\"Authors list: {authors}\")\n",
    "    print(f\"model running on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PORT OF PREPROCESSING SCRIPT USED ON CORPUS\n",
    "\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "def process_line(line: str) -> str:\n",
    "    result = line\n",
    "\n",
    "    # Remove stuff between brackets\n",
    "    bracket_processed = False\n",
    "    if '[' in line and ']' in line:\n",
    "        fst_bracket_idx = line.index('[')\n",
    "        snd_bracket_idx = line.index(']')\n",
    "        if fst_bracket_idx < snd_bracket_idx:\n",
    "            result = result[:fst_bracket_idx] + result[snd_bracket_idx + 1:]\n",
    "            bracket_processed = True\n",
    "    if not bracket_processed and '[' in line:\n",
    "        fst_bracket_idx = line.index('[')\n",
    "        result = result[:fst_bracket_idx]\n",
    "        bracket_processed = True\n",
    "    if not bracket_processed and ']' in line:\n",
    "        snd_bracket_idx = line.index(']')\n",
    "        result = result[snd_bracket_idx + 1:]\n",
    "        bracket_processed = True\n",
    "\n",
    "    # Remove symbols and ALL CAPS words, and normalize punctuation\n",
    "    result = re.sub(r\"[’‘]\", \"'\", result)\n",
    "    result = re.sub(r\"[_,:;\\[\\]\\{\\}\\(\\)—“”&<>$/\\\\=+\\`^~]\", '', result)\n",
    "    result = re.sub(r\"[0-9]\", '', result)\n",
    "    result = result.replace('-', ' ')\n",
    "    result = re.sub(r\"[\\?\\!]\", '.', result)\n",
    "\n",
    "    words = result.split(' ')\n",
    "    words = [word for word in words if not (word.isupper() and len(word) > 1)]\n",
    "    result = ' '.join(words)\n",
    "\n",
    "    return result\n",
    "\n",
    "def process_text(text: str) -> List[str]:\n",
    "    # Remove excess white space and process each line\n",
    "    lines = text.split('\\n')\n",
    "    lines = [line.strip() for line in lines]\n",
    "    lines = [process_line(line) for line in lines]\n",
    "    lines = [line for line in lines if line]\n",
    "    result = ' '.join(lines)\n",
    "\n",
    "    # Clean up sentences\n",
    "    sentences = result.split('.')\n",
    "    sentences = [sentence.strip().lower() for sentence in sentences]\n",
    "    sentences = [sentence.split(' ') for sentence in sentences]\n",
    "    sentences = [[token for token in tokens if token] for tokens in sentences]\n",
    "    sentences = [\n",
    "        [word for word in tokens if not (len(word) == 1 and word in [\n",
    "            'b', 'c', 'f', 'g', 'h', 'j', 'k',\n",
    "            'p', 'q', 'r', 'v', 'w', 'x', 'y', 'z'\n",
    "        ])]\n",
    "        for tokens in sentences\n",
    "    ]\n",
    "    sentences = [' '.join(tokens) for tokens in sentences if len(tokens) > 2]\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POP 0 33 67 108 146\n"
     ]
    }
   ],
   "source": [
    "with open('./corpus-test/witch of edmonton.txt', '+r') as file:\n",
    "# with open('./corpus-test/the two noble kinsmen.txt', '+r') as file:\n",
    "# with open('./corpus-test/timon of athens.txt', '+r') as file:\n",
    "    raw_text = file.read()\n",
    "    sentences = process_text(raw_text)\n",
    "    sentences = [s for s in sentences]\n",
    "    sentences_tokenized = [tokenizer.tokenize(s) for s in sentences]\n",
    "    \n",
    "    MAX_SEQUENCE_LEN = 128  # can go up to 512\n",
    "    bert_inputs = []\n",
    "    bert_inputs_readable = []\n",
    "    bert_input_masks = []\n",
    "\n",
    "    current_input = [\"[CLS]\"]\n",
    "    for s in sentences_tokenized:\n",
    "        if len(s) + 1 + len(current_input) <= MAX_SEQUENCE_LEN - 1:\n",
    "            current_input.extend(s)\n",
    "            current_input.append(\".\")\n",
    "        else:\n",
    "            current_input.append(\"[SEP]\")\n",
    "            mask = [1 for _ in range(len(current_input))]\n",
    "\n",
    "            while len(current_input) != MAX_SEQUENCE_LEN:\n",
    "                current_input.append(\"[PAD]\")\n",
    "                mask.append(0)\n",
    "\n",
    "            bert_inputs.append(tokenizer.convert_tokens_to_ids(current_input))\n",
    "            bert_inputs_readable.append(current_input)\n",
    "            bert_input_masks.append(mask)\n",
    "            current_input = [\"[CLS]\"]\n",
    "\n",
    "    temp_sentences = [\" \".join(s) for s in bert_inputs_readable]\n",
    "    act_1_idx = next((i for i, s in enumerate(temp_sentences) if \"act one magical\" in s), -1)\n",
    "    act_2_idx = next((i for i, s in enumerate(temp_sentences) if \"act two magical\" in s), -1)\n",
    "    act_3_idx = next((i for i, s in enumerate(temp_sentences) if \"act three magical\" in s), -1)\n",
    "    act_4_idx = next((i for i, s in enumerate(temp_sentences) if \"act four magical\" in s), -1)\n",
    "    act_5_idx = next((i for i, s in enumerate(temp_sentences) if \"act five magical\" in s), -1)\n",
    "    print(\"POP\", act_1_idx, act_2_idx, act_3_idx, act_4_idx, act_5_idx)\n",
    "\n",
    "    scene_1_idxs = [i for i, s in enumerate(temp_sentences) if \"scene one magical\" in s]\n",
    "    scene_2_idxs = [i for i, s in enumerate(temp_sentences) if \"scene two magical\" in s]\n",
    "    scene_3_idxs = [i for i, s in enumerate(temp_sentences) if \"scene three magical\" in s]\n",
    "    scene_4_idxs = [i for i, s in enumerate(temp_sentences) if \"scene four magical\" in s]\n",
    "    scene_5_idxs = [i for i, s in enumerate(temp_sentences) if \"scene five magical\" in s]\n",
    "\n",
    "    x_inputs = torch.tensor(bert_inputs).to(device)\n",
    "    x_masks = torch.tensor(bert_input_masks).to(device)\n",
    "\n",
    "delimiter_idx = [act_1_idx, act_2_idx, act_3_idx, act_4_idx, act_5_idx]\n",
    "delimiter_scene_idx = scene_1_idxs + scene_2_idxs + scene_3_idxs + scene_4_idxs + scene_5_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN INFERENCE\n",
    "# model.eval()\n",
    "# outputs = model(x_inputs, token_type_ids=None, attention_mask=x_masks, output_attentions=True) \n",
    "# logits = outputs.logits.detach().cpu().numpy()\n",
    "\n",
    "batch_size = 16\n",
    "logits_list = []\n",
    "for i in range(0, len(x_inputs), batch_size):\n",
    "    batch_inputs = x_inputs[i:i+batch_size]\n",
    "    batch_masks = x_masks[i:i+batch_size]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch_inputs, token_type_ids=None, attention_mask=batch_masks, output_attentions=True)\n",
    "        logits = outputs.logits.detach().cpu().numpy()\n",
    "    logits_list.append(logits)\n",
    "\n",
    "logits = np.concatenate(logits_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 16, 14, 14, 11, 17, 16, 11, 14, 16, 16, 16, 16, 11, 17, 16, 16, 12, 14, 11, 2, 2, 16, 16, 16, 12, 17, 2, 12, 14, 16, 16, 14, 9, 17, 9, 10, 12, 12, 17, 12, 9, 12, 10, 9, 9, 16, 14, 12, 17, 12, 12, 10, 14, 12, 2, 10, 11, 11, 12, 11, 2, 11, 16, 14, 2, 2, 14, 14, 12, 16, 16, 9, 16, 12, 17, 16, 0, 16, 12, 16, 14, 16, 14, 14, 11, 17, 12, 12, 2, 11, 16, 13, 17, 13, 17, 9, 16, 16, 2, 16, 16, 12, 14, 12, 0, 2, 16, 11, 0, 9, 16, 10, 16, 9, 9, 9, 0, 12, 17, 16, 0, 0, 0, 12, 9, 14, 14, 16, 12, 0, 17, 11, 15, 11, 14, 16, 0, 16, 9, 0, 12, 9, 12, 14, 16, 16, 11, 17, 17, 0, 0, 9, 14, 10, 16, 16, 12, 10, 11, 12, 17, 9, 16, 11, 14, 9, 13, 12, 11, 2, 16, 2, 10, 16, 11]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "test = np.argmax(logits, axis=1).flatten()\n",
    "for i in range(logits.shape[0]):        \n",
    "    distribution = logits[i].copy()\n",
    "    mi = np.argmax(distribution)\n",
    "\n",
    "    if mi == 0 or mi == 2 or mi == 6: # or mi == 8:\n",
    "        results.append(mi)\n",
    "    else:\n",
    "        # distribution[1] = 0; distribution[3] = 0; distribution[4] = 0\n",
    "        # distribution[5] = 0; distribution[7] = 0\n",
    "        distribution[mi] = 0\n",
    "        mi = np.argmax(distribution)\n",
    "        results.append(mi + 9)\n",
    "\n",
    "    # if mi == 1 or mi == 7:\n",
    "    #     results.append(mi)\n",
    "    # else:\n",
    "    #     distribution[0] = 0; distribution[2] = 0; distribution[3] = 0\n",
    "    #     distribution[4] = 0; distribution[5] = 0; distribution[6] = 0; distribution[8] = 0\n",
    "    #     mi = np.argmax(distribution)\n",
    "    #     results.append(mi + 9)\n",
    "\n",
    "    # if mi == 7 or mi == 5:\n",
    "    #     results.append(mi)\n",
    "    # else:\n",
    "    #     distribution[0] = 0; distribution[2] = 0; distribution[3] = 0\n",
    "    #     distribution[4] = 0; distribution[6] = 0; distribution[1] = 0; distribution[8] = 0\n",
    "    #     mi = np.argmax(distribution)\n",
    "    #     results.append(mi + 9)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 8, 1, 1, 7, 5, 4, 4, 1, 4, 5, 3, 8, 5, 7, 5, 5, 1, 1, 7, 2, 2, 3, 3, 5, 5, 4, 2, 5, 8, 4, 3, 5, 7, 7, 7, 5, 7, 7, 5, 7, 5, 1, 7, 7, 1, 1, 5, 7, 7, 7, 1, 5, 7, 7, 2, 5, 7, 1, 5, 5, 2, 7, 8, 3, 2, 2, 7, 3, 7, 3, 8, 7, 3, 7, 7, 3, 0, 3, 5, 3, 7, 5, 4, 3, 3, 1, 5, 5, 2, 5, 5, 1, 3, 8, 5, 8, 1, 5, 2, 3, 3, 5, 3, 5, 0, 2, 3, 5, 0, 7, 5, 5, 3, 1, 8, 7, 0, 7, 5, 1, 0, 0, 0, 7, 5, 8, 3, 3, 7, 0, 5, 7, 5, 1, 3, 3, 0, 8, 8, 0, 5, 7, 7, 1, 8, 5, 1, 7, 7, 0, 0, 7, 1, 5, 1, 3, 1, 5, 7, 7, 3, 7, 4, 7, 8, 7, 5, 7, 1, 2, 3, 2, 1, 5, 7]\n",
      "[11, 16, 14, 14, 11, 17, 16, 11, 14, 16, 16, 16, 16, 11, 17, 16, 16, 12, 14, 11, 2, 2, 16, 16, 16, 12, 17, 2, 12, 14, 16, 16, 14, 9, 17, 9, 10, 12, 12, 17, 12, 9, 12, 10, 9, 9, 16, 14, 12, 17, 12, 12, 10, 14, 12, 2, 10, 11, 11, 12, 11, 2, 11, 16, 14, 2, 2, 14, 14, 12, 16, 16, 9, 16, 12, 17, 16, 0, 16, 12, 16, 14, 16, 14, 14, 11, 17, 12, 12, 2, 11, 16, 13, 17, 13, 17, 9, 16, 16, 2, 16, 16, 12, 14, 12, 0, 2, 16, 11, 0, 9, 16, 10, 16, 9, 9, 9, 0, 12, 17, 16, 0, 0, 0, 12, 9, 14, 14, 16, 12, 0, 17, 11, 15, 11, 14, 16, 0, 16, 9, 0, 12, 9, 12, 14, 16, 16, 11, 17, 17, 0, 0, 9, 14, 10, 16, 16, 12, 10, 11, 12, 17, 9, 16, 11, 14, 9, 13, 12, 11, 2, 16, 2, 10, 16, 11]\n",
      "[0, 33, 67, 108, 146]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAABhCAYAAABRTdfNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAExklEQVR4nO3bTXLiRhgG4JbLuxTsQ8Ep5gBx9nOOuYbta+Qcc4BcYE6Bi+xhUuUVyspTRRNo2rwEnHmenUZy65P6089bGoZxHMcCAAAQdHftAgAAgP8fQQMAAIgTNAAAgDhBAwAAiBM0AACAOEEDAACIEzQAAIA4QQMAAIi7P2Wj7XZbVqtVmUwmZRiGS9cEAADcqHEcy2azKbPZrNzdHf5ucVLQWK1WZbFYxIoDAAA+tuVyWebz+cH1JwWNyWTyY7DpdJqpDAAA+HDW63VZLBY/MsIhJwWNt/8uNZ1OBQ0AAKD5kwo/BgcAAOJO+qJxc+r0NI7XqYPboB84Rn9wa/Qkl6S/uCG+aAAAAHGCBgAAECdoAAAAcYIGAAAQJ2gAAABxggYAABAnaAAAAHGCBgAAECdoAAAAcYIGAAAQJ2gAAABxggYAABAnaAAAAHH31y6AtmEYdpbHcbxSJfyM9N9t+wjzc+s13np9nMf8/lzM923xRQMAAIgTNAAAgDhBAwAAiBM0AACAOEEDAACIEzQAAIA4QQMAAIgTNAAAgDhBAwAAiBM0AACAOEEDAACIEzQAAIA4QQMAAIgTNAAAgLj7axdwDc/fdpd/+7q7/PB4fPvHT/9tPenxnxrjj4/H17f8+by7/Ht4/N79P3yp/uHXvgL2xqv//K/O8evta+n6Lqzur1p9vbT68enz8b+vDY3TOR5f3a9zvpvz8zzsLj/GKz6q9374b+o5qOewpXWOzr2m6/ri96BqDoeq65r7q3vgy9Pucuc9oXmPqf1R7a/qwe4ebql7vPce2tKop+75z5929//12+7+m8/81jVcH1/jfKfPR+87xkNpzOe5/dmp9Q5W9+e54/We/9Yzrb7+e+9Hl34HvTRfNAAAgDhBAwAAiBM0AACAOEEDAACIEzQAAIA4QQMAAIgTNAAAgDhBAwAAiBM0AACAOEEDAACIEzQAAIA4QQMAAIgTNAAAgDhBAwAAiBM0AACAOEEDAACIEzQAAIA4QQMAAIgTNAAAgDhBAwAAiBM0AACAOEEDAACIEzQAAIA4QQMAAIgTNAAAgDhBAwAAiBM0AACAOEEDAACIEzQAAIA4QQMAAIgTNAAAgDhBAwAAiBM0AACAOEEDAACIEzQAAIA4QQMAAIgTNAAAgDhBAwAAiBM0AACAOEEDAACIEzQAAIA4QQMAAIi7P2WjcRxLKaWs1+uLFvNunXW9ft9d/vv1+HD19unT0Kqn1jsP9filOX7X8Hva9Z83fnv/uztYb6qCfukroNUfpXf8evtaur6wuv/2+mtv+93lVj92X2+tfmsV1KtzvpvzU9d/Zn3n3h/e1U+NOazVNbb2ube+95rrPKbuZ91eD1b3oN4ePvOe1bzHtPbfOT+ta3BPPcC5x1tr1PP6fXf87+vXo+u75691fL3bn3k+6uNpPqNbA6bnq6H1TOh9Z2o+YzqPr/VMa10vrf669Dvoe72d17eMcMgwtrYopby8vJTFYpGpDAAA+PCWy2WZz+cH158UNLbbbVmtVmUymZRhGKIFAgAAH8c4jmWz2ZTZbFbu7g7/EuOkoAEAANDDj8EBAIA4QQMAAIgTNAAAgDhBAwAAiBM0AACAOEEDAACIEzQAAIC4fwDVLn6cgWwuJwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "print(list(pred_flat))\n",
    "print(list(results))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "data = results\n",
    "def recolor(i):\n",
    "    if i == -1:\n",
    "        return [0, 0, 0]\n",
    "    \n",
    "    if i == 0:  # dekker, orange\n",
    "        return [1, 0.5, 0]\n",
    "    elif i == 0 + 9:  # dekker, orange\n",
    "        return [1, 0.9, 0.5]\n",
    "    elif i == 6: # rowley, green\n",
    "        return [0.5, 1, 0]\n",
    "    elif i == 6 + 9: # rowley, green\n",
    "        return [0.8, 1, 0.5]\n",
    "    elif i == 2: # ford, blue\n",
    "        return [0, 0.5, 1]\n",
    "    elif i == 2 + 9: # ford, blue\n",
    "        return [0.5, 0.8, 1]\n",
    "    elif i == 8: # webster, purple\n",
    "        return [0.5, 0, 1]\n",
    "    elif i == 8 + 9: # webster, purple\n",
    "        return [0.75, 0.5, 1]\n",
    "    \n",
    "    # if i == 7:  # shakespeare, yellow\n",
    "    #     return [1, 1, 0]\n",
    "    # elif i == 7 + 9:  # shakespeare, yellow\n",
    "    #     return [1, 1, 0.5]\n",
    "    # elif i == 1: # fletcher, blue\n",
    "    #     return [0.2, 0.3, 0.8]\n",
    "    # elif i == 1 + 9: # fletcher, blue\n",
    "    #     return [0.6, 0.7, 0.9]\n",
    "\n",
    "    # if i == 7:  # shakespeare, yellow\n",
    "    #     return [1, 1, 0]\n",
    "    # # elif i == 7 + 9:  # shakespeare, yellow\n",
    "    # #     return [1, 1, 0.5]\n",
    "    # elif i == 5: # middleton, blue\n",
    "    #     return [0, 1, 1]\n",
    "    # # elif i == 5 + 9: # middleton, blue\n",
    "    # #     return [0.5, 1, 1]\n",
    "\n",
    "    return [1, 1, 1]\n",
    "\n",
    "print(delimiter_idx)\n",
    "colors = [recolor(-1 if i in delimiter_scene_idx else data[i]) for i in range(len(data))]\n",
    "colors = [([1, 0, 0] if i in delimiter_idx else colors[i] )for i in range(len(data))]\n",
    "heights = [(0.8 if i in delimiter_scene_idx else 0.6) for i in range(len(data))]\n",
    "heights = [(1.0 if i in delimiter_idx else heights[i]) for i in range(len(data))]\n",
    "positions = np.arange(len(data))\n",
    "fig, ax = plt.subplots(figsize=(10, 1))\n",
    "ax.bar(positions, heights, color=colors, width=1.0, edgecolor=\"none\")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[195], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(authors)\n\u001b[1;32m----> 7\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar(x,y)\n",
      "File \u001b[1;32mc:\\Users\\kauhe\\anaconda3\\envs\\authorship-problem\\Lib\\site-packages\\torch\\nn\\functional.py:2138\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   2134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2135\u001b[0m         softmax, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, dim\u001b[38;5;241m=\u001b[39mdim, _stacklevel\u001b[38;5;241m=\u001b[39m_stacklevel, dtype\u001b[38;5;241m=\u001b[39mdtype\n\u001b[0;32m   2136\u001b[0m     )\n\u001b[0;32m   2137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2138\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m(), _stacklevel)\n\u001b[0;32m   2139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2140\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "# PLOT CLASSIFICATION LOGITS\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.array(authors)\n",
    "y = np.array(F.softmax(logits).detach().numpy()[0])\n",
    "\n",
    "plt.figure(figsize=(16, 3))\n",
    "plt.bar(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = outputs.attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 12, 128, 128])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "authorship-problem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
